<!DOCTYPE html>
<html>
<!-- This is an automatically generated file.  Do not edit.
   -*- nroff -*-
 -->
<head>
  <meta charset="utf-8"/>
  <link rel="stylesheet" href="../style.css" type="text/css" media="all"/>
  <title>MPSRNNMatrixInferenceLayer(3)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPSRNNMatrixInferenceLayer(3)</td>
    <td class="head-vol">MetalPerformanceShaders.framework</td>
    <td class="head-rtitle">MPSRNNMatrixInferenceLayer(3)</td>
  </tr>
</table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
<p class="Pp">MPSRNNMatrixInferenceLayer</p>
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<p class="Pp">#import &lt;MPSRNNLayer.h&gt;</p>
<p class="Pp">Inherits <b>MPSKernel</b>.</p>
<section class="Ss">
<h2 class="Ss" id="Instance_Methods"><a class="permalink" href="#Instance_Methods">Instance
  Methods</a></h2>
<br/>
<p class="Pp">(nonnull instancetype) - <b>initWithDevice:rnnDescriptor:</b>
  <br/>
  (nonnull instancetype) - <b>initWithDevice:rnnDescriptors:</b>
  <br/>
  (nonnull instancetype) - <b>initWithDevice:</b>
  <br/>
  (void) -
    <b>encodeSequenceToCommandBuffer:sourceMatrices:sourceOffsets:destinationMatrices:destinationOffsets:recurrentInputState:recurrentOutputStates:</b>
  <br/>
  (void) -
    <b>encodeSequenceToCommandBuffer:sourceMatrices:destinationMatrices:recurrentInputState:recurrentOutputStates:</b>
  <br/>
  (void) -
    <b>encodeBidirectionalSequenceToCommandBuffer:sourceSequence:destinationForwardMatrices:destinationBackwardMatrices:</b>
  <br/>
  (nullable instancetype) - <b>initWithCoder:device:</b>
  <br/>
  (nonnull instancetype) - <b>copyWithZone:device:</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Properties"><a class="permalink" href="#Properties">Properties</a></h2>
<br/>
<p class="Pp">NSUInteger <b>inputFeatureChannels</b>
  <br/>
  NSUInteger <b>outputFeatureChannels</b>
  <br/>
  NSUInteger <b>numberOfLayers</b>
  <br/>
  BOOL <b>recurrentOutputIsTemporary</b>
  <br/>
  BOOL <b>storeAllIntermediateStates</b>
  <br/>
  <b>MPSRNNBidirectionalCombineMode</b> <b>bidirectionalCombineMode</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Additional_Inherited_Members"><a class="permalink" href="#Additional_Inherited_Members">Additional
  Inherited Members</a></h2>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Detailed_Description"><a class="permalink" href="#Detailed_Description">Detailed
  Description</a></h1>
<p class="Pp">This depends on Metal.framework The
    <b>MPSRNNMatrixInferenceLayer</b> specifies a recurrent neural network layer
    for inference on MPSMatrices. Currently two types of recurrent layers are
    supported: ones that operate with convolutions on images:
    <b>MPSRNNImageInferenceLayer</b> and one that operates on matrices:
    <b>MPSRNNMatrixInferenceLayer</b>. The former can be often used to implement
    the latter by using 1x1-matrices, but due to image size restrictions and
    performance, it is advisable to use <b>MPSRNNMatrixInferenceLayer</b> for
    linear recurrent layers. <b>A</b> <b>MPSRNNMatrixInferenceLayer</b> is
    initialized using a <b>MPSRNNLayerDescriptor</b>, which further specifies
    the recurrent network layer, or an array of <b>MPSRNNLayerDescriptors</b>,
    which specifies a stack of recurrent layers, that can operate in parallel a
    subset of the inputs in a sequence of inputs and recurrent outputs. Note
    that currently stacks with bidirectionally traversing encode functions do
    not support starting from a previous set of recurrent states, but this can
    be achieved quite easily by defining two separate unidirectional stacks of
    layers, and running the same input sequence on them separately (one forwards
    and one backwards) and ultimately combining the two result sequences as
    desired with auxiliary functions. The input and output vectors in encode
    calls are stored as rows of the input and output matrices and
    <b>MPSRNNMatrixInferenceLayer</b> supports matrices with decreasing number
    of rows: The row-indices identify the different sequences that may be of
    different lengths - for example if we have three sequences: ( x1, x2, x3 ),
    ( y1, y2, y3, y4 ) and ( z1, z2 ) of vectors xi, yi and zi, then these can
    be inserted together as a batch to the sequence encoding kernel by using the
    matrices:</p>
<p class="Pp"></p>
<pre>
<br/>
     ( y1 )        ( y2 )        ( y3 )        ( y4 )
m1 = ( x1 ),  m2 = ( x2 ),  m3 = ( x3 ),  m4 =
<br/>
     ( z1 )        ( z2 )
</pre>
<p class="Pp">
  <br/>
   If a recurrent output state is requested then it will contain the state
    corresponding to last inputs to each sequence and if all the intermediate
    states are requested (see storeAllIntermediateStates), then the shorter
    sequences will be propagated by copying the state of the previous output if
    the input vector is not present in the sequence - in the example above the
    output states would be:</p>
<p class="Pp"></p>
<pre>
<br/>
     ( s_y1 )        ( s_y2 )        ( s_y3 )        ( s_y4 )
s1 = ( s_x1 ),  s2 = ( s_x2 ),  s3 = ( s_x3 ),  s4 = ( s_x3 )
<br/>
     ( s_z1 )        ( s_z2 )        ( s_z2 )        ( s_z2 )
</pre>
<p class="Pp">
  <br/>
   The mathematical operation described in the linear transformations of
    <b>MPSRNNSingleGateDescriptor</b> <b>MPSLSTMDescriptor</b> and
    <b>MPSGRUDescriptor</b> are y^T = W x^T &lt;=&gt; y = x W^T, where x is the
    matrix containing the input vectors as rows, y is the matrix containing the
    output vectors as rows and W is the weight matrix.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="Method_Documentation"><a class="permalink" href="#Method_Documentation">Method
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) copyWithZone: (nullable NSZone *)
  zone(nullable id&lt; MTLDevice &gt;) device</h2>
<p class="Pp">Make a copy of this kernel for a new device -</p>
<p class="Pp"><b>See also:</b></p>
<div class="Bd-indent"><b>MPSKernel</b></div>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>zone</i> The NSZone in which to allocate the object
<br/>
<i>device</i> The device for the new <b>MPSKernel</b>. If nil, then use
  self.device.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">a pointer to a copy of this <b>MPSKernel</b>. This will
  fail, returning nil if the device is not supported. Devices must be
  MTLFeatureSet_iOS_GPUFamily2_v1 or later.</div>
<p class="Pp">Reimplemented from <b>MPSKernel</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (void) encodeBidirectionalSequenceToCommandBuffer: (nonnull
  id&lt; MTLCommandBuffer &gt;) commandBuffer(NSArray&lt; <b>MPSMatrix</b> *
  &gt; *__nonnull) sourceSequence(NSArray&lt; <b>MPSMatrix</b> * &gt;
  *__nonnull) destinationForwardMatrices(NSArray&lt; <b>MPSMatrix</b> * &gt;
  *__nullable) destinationBackwardMatrices</h2>
<p class="Pp">Encode an <b>MPSRNNMatrixInferenceLayer</b> kernel stack for an
    input matrix sequences into a command buffer bidirectionally. The operation
    proceeds as follows: The first source matrix x0 is passed through all
    forward traversing layers in the stack, ie. those that were initialized with
    MPSRNNSequenceDirectionForward, recurrent input is assumed zero. This
    produces forward output yf0 and recurrent states hf00, hf01, hf02, ... hf0n,
    one for each forward layer in the stack. Then x1 is passed to forward layers
    together with recurrent state hf00, hf01, ..., hf0n, which produces yf1, and
    hf10,... This procedure is iterated until the last matrix in the input
    sequence x_(N-1), which produces forward output yf(N-1). The backwards
    layers iterate the same sequence backwards, starting from input x_(N-1)
    (recurrent state zero), that produces yb(N-1) and recurrent output hb(N-1)0,
    hf(N-1)1, ... hb(N-1)m, one for each backwards traversing layer. Then the
    backwards layers handle input x_(N-2) using recurrent state hb(N-1)0, ...,
    et cetera, until the first matrix of the sequence is computed, producing
    output yb0. The result of the operation is either pair of sequences ({yf0,
    yf1, ... , yf(N-1)}, {yb0, yb1, ... , yb(N-1)}) or a combined sequence,
    {(yf0 + yb0), ... , (yf(N-1) + yb(N-1)) }, where '+' stands either for sum,
    or concatenation along feature channels, as specified by
    <b>bidirectionalCombineMode</b>.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded filter
<br/>
<i>sourceSequence</i> An array of valid <b>MPSMatrix</b> objects containing the
  source matrix sequence (x0, x1, ... x_n-1).
<br/>
<i>destinationForwardMatrices</i> An array of valid MPSMatrices to be
  overwritten by result from forward input matrices. If bidirectionalCombineMode
  is either MPSRNNBidirectionalCombineModeAdd or
  MPSRNNBidirectionalCombineModeConcatenate, then will contain the combined
  results. destinationForwardMatrix may not alias with any of the source
  matrices.
<br/>
<i>destinationBackwardMatrices</i> If bidirectionalCombineMode is
  MPSRNNBidirectionalCombineModeNone, then must be an array of valid MPSMatrices
  that will be overwritten by result from backward input matrices. Otherwise
  this parameter is ignored and can be nil. destinationBackwardMatrices may not
  alias to any of the source matrices.</div>
</section>
<section class="Ss">
<h2 class="Ss">- (void) encodeSequenceToCommandBuffer: (nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(NSArray&lt; <b>MPSMatrix</b> * &gt;
  *__nonnull) sourceMatrices(NSArray&lt; <b>MPSMatrix</b> * &gt; *__nonnull)
  destinationMatrices(<b>MPSRNNRecurrentMatrixState</b> *__nullable)
  recurrentInputState(NSMutableArray&lt; <b>MPSRNNRecurrentMatrixState</b> *
  &gt; *__nullable) recurrentOutputStates</h2>
</section>
<section class="Ss">
<h2 class="Ss">- (void) encodeSequenceToCommandBuffer: (nonnull id&lt;
  MTLCommandBuffer &gt;) commandBuffer(NSArray&lt; <b>MPSMatrix</b> * &gt;
  *__nonnull) sourceMatrices(NSUInteger *__nullable) sourceOffsets(NSArray&lt;
  <b>MPSMatrix</b> * &gt; *__nonnull) destinationMatrices(NSUInteger
  *__nullable) destinationOffsets(<b>MPSRNNRecurrentMatrixState</b> *__nullable)
  recurrentInputState(NSMutableArray&lt; <b>MPSRNNRecurrentMatrixState</b> *
  &gt; *__nullable) recurrentOutputStates</h2>
<p class="Pp">Encode an <b>MPSRNNMatrixInferenceLayer</b> kernel (stack) for a
    sequence of inputs into a command buffer. Note that when encoding using this
    function the</p>
<p class="Pp"><b>See also:</b></p>
<div class="Bd-indent">layerSequenceDirection is ignored and the layer stack
  operates as if all layers were forward feeding layers. In order to run
  bidirectional sequences use
  <b>encodeBidirectionalSequenceToCommandBuffer:sourceSequence:</b> or
  alternatively run two layer stacks and combine results at the end using
  utility functions.</div>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>commandBuffer</i> <b>A</b> valid MTLCommandBuffer to
  receive the encoded filter
<br/>
<i>sourceMatrices</i> An array of valid <b>MPSMatrix</b> objects containing the
  sequence of source matrices.
<br/>
<i>sourceOffsets</i> An array of byte-offsets into the sourceMatrices, if nil
  zeros are assumed and if not nil must contain offset for every matrix in
  sourceMatrices.
<br/>
<i>destinationMatrices</i> An array valid MPSMatrices to be overwritten by
  result matrix sequence. destinationMatrices may not alias sourceMatrices.
<br/>
<i>destinationOffsets</i> An array of byte-offsets into the destinationMatrices,
  if nil zeros are assumed and if not nil must contain offset for every matrix
  in destinationMatrices.
<br/>
<i>recurrentInputState</i> An optional state containing the output matrices and
  memory cells (for LSTMs) of the layer obtained from the previous input
  matrices in a sequence of inputs. Has to be the output of a previous call to
  this function or nil (assumed zero). Note: can be one of the states returned
  in <b>intermediateRecurrentStates</b>.
<br/>
<i>recurrentOutputStates</i> An optional array that will contain the recurrent
  output states. If nil then the recurrent output state is discarded. If
  <b>storeAllIntermediateStates</b> is YES, then all intermediate states of the
  sequence are returned in the array, the first one corresponding to the first
  input in the sequence, otherwise only the last recurrent output state is
  returned. If recurrentOutputIsTemporary is YES and then all returned recurrent
  states will be temporary.</div>
<p class="Pp"><b>See also:</b></p>
<div class="Bd-indent"><b>MPSState</b>:isTemporary. Example: In order to get a
  new state one can do the following:
<p class="Pp"></p>
<pre>
MPSRNNRecurrentMatrixState* recurrent0 = nil;
[filter encodeToCommandBuffer: cmdBuf
<br/>
                 sourceMatrix: source0
<br/>
            destinationMatrix: destination0
<br/>
          recurrentInputState: nil
<br/>
         recurrentOutputState: &amp;recurrent0];
</pre>
<p class="Pp">
  <br/>
   Then use it for the next input in sequence:</p>
<p class="Pp"></p>
<pre>
[filter encodeToCommandBuffer: cmdBuf
<br/>
                 sourceMatrix: source1
<br/>
            destinationMatrix: destination1
<br/>
          recurrentInputState: recurrent0
<br/>
         recurrentOutputState: &amp;recurrent0];
</pre>
<p class="Pp">
  <br/>
   And discard recurrent output of the third input:</p>
<p class="Pp"></p>
<pre>
[filter encodeToCommandBuffer: cmdBuf
<br/>
                 sourceMatrix: source2
<br/>
            destinationMatrix: destination2
<br/>
          recurrentInputState: recurrent0
<br/>
         recurrentOutputState: nil];
</pre>
</div>
</section>
<section class="Ss">
<h2 class="Ss">- (nullable instancetype) <b>initWithCoder:</b> (NSCoder
  *__nonnull) aDecoder(nonnull id&lt; MTLDevice &gt;) device</h2>
<p class="Pp"><b>NSSecureCoding</b> compatability See
    <b>MPSKernel::initWithCoder</b>.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>aDecoder</i> The NSCoder subclass with your serialized
  <b>MPSRNNMatrixInferenceLayer</b>
<br/>
<i>device</i> The MTLDevice on which to make the
  <b>MPSRNNMatrixInferenceLayer</b></div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> new <b>MPSRNNMatrixInferenceLayer</b> object, or
  nil if failure.</div>
<p class="Pp">Reimplemented from <b>MPSKernel</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) initWithDevice: (nonnull id&lt;
  MTLDevice &gt;) device</h2>
<p class="Pp">Standard init with default properties per filter type</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The device that the filter will be used on.
  May not be NULL.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">a pointer to the newly initialized object. This will
  fail, returning nil if the device is not supported. Devices must be
  MTLFeatureSet_iOS_GPUFamily2_v1 or later.</div>
<p class="Pp">Reimplemented from <b>MPSKernel</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) <b>initWithDevice:</b> (nonnull id&lt;
  MTLDevice &gt;) device(nonnull const <b>MPSRNNDescriptor</b> *)
  rnnDescriptor</h2>
<p class="Pp">Initializes a linear (fully connected) RNN kernel</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The MTLDevice on which this
  MPSRNNMatrixLayer filter will be used
<br/>
<i>rnnDescriptor</i> The descriptor that defines the RNN layer</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSRNNMatrixInferenceLayer</b> object
  or nil, if failure.</div>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) <b>initWithDevice:</b> (nonnull id&lt;
  MTLDevice &gt;) device(NSArray&lt; const <b>MPSRNNDescriptor</b> * &gt;
  *__nonnull) rnnDescriptors</h2>
<p class="Pp">Initializes a kernel that implements a stack of linear (fully
    connected) RNN layers</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>device</i> The MTLDevice on which this
  MPSRNNMatrixLayer filter will be used
<br/>
<i>rnnDescriptors</i> An array of RNN descriptors that defines a stack of RNN
  layers, starting at index zero. The number of layers in stack is the number of
  entries in the array. All entries in the array must be valid
  MPSRNNDescriptors.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSRNNMatrixInferenceLayer</b> object
  or nil, if failure.</div>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Property_Documentation"><a class="permalink" href="#Property_Documentation">Property
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- bidirectionalCombineMode [read]<b>, [write]</b>,
  [nonatomic]<b>, [assign]</b></h2>
<p class="Pp">Defines how to combine the output-results, when encoding
    bidirectional layers using
    <b>encodeBidirectionalSequenceToCommandBuffer</b>. Defaults to
    <b>MPSRNNBidirectionalCombineModeNone</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- inputFeatureChannels [read]<b>, [nonatomic]</b>,
  [assign]<b></b></h2>
<p class="Pp">The number of feature channels input vector/matrix.</p>
</section>
<section class="Ss">
<h2 class="Ss">- numberOfLayers [read]<b>, [nonatomic]</b>, [assign]<b></b></h2>
<p class="Pp">Number of layers in the filter-stack. This will be one when using
    initWithDevice:rnnDescriptor to initialize this filter and the number of
    entries in the array 'rnnDescriptors' when initializing this filter with
    initWithDevice:rnnDescriptors.</p>
</section>
<section class="Ss">
<h2 class="Ss">- outputFeatureChannels [read]<b>, [nonatomic]</b>,
  [assign]<b></b></h2>
<p class="Pp">The number of feature channels in the output vector/matrix.</p>
</section>
<section class="Ss">
<h2 class="Ss">- recurrentOutputIsTemporary [read]<b>, [write]</b>,
  [nonatomic]<b>, [assign]</b></h2>
<p class="Pp">How output states from <b>encodeSequenceToCommandBuffer</b> are
    constructed. Defaults to NO. For reference</p>
<p class="Pp"><b>See also:</b></p>
<div class="Bd-indent"><b>MPSState</b>.</div>
</section>
<section class="Ss">
<h2 class="Ss">- storeAllIntermediateStates [read]<b>, [write]</b>,
  [nonatomic]<b>, [assign]</b></h2>
<p class="Pp">If YES then calls to <b>encodeSequenceToCommandBuffer</b> return
    every recurrent state in the array: recurrentOutputStates. Defaults to
  NO.</p>
<p class="Pp"></p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Author"><a class="permalink" href="#Author">Author</a></h1>
<p class="Pp">Generated automatically by Doxygen for
    MetalPerformanceShaders.framework from the source code.</p>
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">Mon Jul 9 2018</td>
    <td class="foot-os">Version MetalPerformanceShaders-119.3</td>
  </tr>
</table>
</body>
</html>
