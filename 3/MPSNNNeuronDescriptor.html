<!DOCTYPE html>
<html lang="en">
<!-- This is an automatically generated file.  Do not edit.
   -*- nroff -*-
 -->
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <link rel="stylesheet" href="../style.css" type="text/css" media="all"/>
  <title>MPSNNNeuronDescriptor(3)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPSNNNeuronDescriptor(3)</td>
    <td class="head-vol"><a href=".">MetalPerformanceShaders.framework</a></td>
    <td class="head-rtitle">MPSNNNeuronDescriptor(3)</td>
  </tr>
</table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
<p class="Pp">MPSNNNeuronDescriptor</p>
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<p class="Pp">#import &lt;MPSCNNNeuron.h&gt;</p>
<p class="Pp">Inherits NSObject, and &lt;NSCopying&gt;.</p>
<section class="Ss">
<h2 class="Ss" id="Instance_Methods"><a class="permalink" href="#Instance_Methods">Instance
  Methods</a></h2>
<br/>
<p class="Pp">(nonnull instancetype) - <b>init</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Class_Methods"><a class="permalink" href="#Class_Methods">Class
  Methods</a></h2>
<br/>
<p class="Pp">(nonnull <b>MPSNNNeuronDescriptor</b> *) +
    <b>cnnNeuronDescriptorWithType:</b>
  <br/>
  (nonnull <b>MPSNNNeuronDescriptor</b> *) +
    <b>cnnNeuronDescriptorWithType:a:</b>
  <br/>
  (nonnull <b>MPSNNNeuronDescriptor</b> *) +
    <b>cnnNeuronDescriptorWithType:a:b:</b>
  <br/>
  (nonnull <b>MPSNNNeuronDescriptor</b> *) +
    <b>cnnNeuronDescriptorWithType:a:b:c:</b>
  <br/>
  (nonnull <b>MPSNNNeuronDescriptor</b> *) +
    <b>cnnNeuronPReLUDescriptorWithData:noCopy:</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Properties"><a class="permalink" href="#Properties">Properties</a></h2>
<br/>
<p class="Pp"><b>MPSCNNNeuronType</b> <b>neuronType</b>
  <br/>
  float <b>a</b>
  <br/>
  float <b>b</b>
  <br/>
  float <b>c</b>
  <br/>
  NSData * <b>data</b>
  <br/>
  <br/>
</p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Detailed_Description"><a class="permalink" href="#Detailed_Description">Detailed
  Description</a></h1>
<p class="Pp">This depends on Metal.framework The <b>MPSNNNeuronDescriptor</b>
    specifies a neuron descriptor. Supported neuron types:</p>
<p class="Pp">Neuron type 'none': f(x) = x Parameters: none</p>
<p class="Pp">ReLU neuron filter: f(x) = x &gt;= 0 ? x : a * x This is called
    Leaky ReLU in literature. Some literature defines classical ReLU as max(0,
    x). If you want this behavior, simply pass a = 0. Parameters: a For default
    behavior, set the value of a to 0.0f.</p>
<p class="Pp">Linear neuron filter: f(x) = a * x + b Parameters: a, b For
    default behavior, set the value of a to 1.0f and the value of b to 0.0f.</p>
<p class="Pp">Sigmoid neuron filter: f(x) = 1 / (1 + e^-x) Parameters: none</p>
<p class="Pp">Hard Sigmoid filter: f(x) = clamp((x * a) + b, 0, 1) Parameters:
    a, b For default behavior, set the value of a to 0.2f and the value of b to
    0.5f.</p>
<p class="Pp">Hyperbolic tangent (TanH) neuron filter: f(x) = a * tanh(b * x)
    Parameters: a, b For default behavior, set the value of a to 1.0f and the
    value of b to 1.0f.</p>
<p class="Pp">Absolute neuron filter: f(x) = fabs(x) Parameters: none</p>
<p class="Pp">Parametric Soft Plus neuron filter: f(x) = a * log(1 + e^(b * x))
    Parameters: a, b For default behavior, set the value of a to 1.0f and the
    value of b to 1.0f.</p>
<p class="Pp">Parametric Soft Sign neuron filter: f(x) = x / (1 + abs(x))
    Parameters: none</p>
<p class="Pp">Parametric ELU neuron filter: f(x) = x &gt;= 0 ? x : a * (exp(x) -
    1) Parameters: a For default behavior, set the value of a to 1.0f.</p>
<p class="Pp">Parametric ReLU (PReLU) neuron filter: Same as ReLU, except
    parameter aArray is per channel. For each pixel, applies the following
    function: f(x_i) = x_i, if x_i &gt;= 0 = a_i * x_i if x_i &lt; 0 i in
    [0...channels-1] i.e. parameters a_i are learned and applied to each channel
    separately. Compare this to ReLu where parameter a is shared across all
    channels. See https://arxiv.org/pdf/1502.01852.pdf for details. Parameters:
    aArray - Array of floats containing per channel value of PReLu parameter
    count - Number of float values in array aArray.</p>
<p class="Pp">ReLUN neuron filter: f(x) = min((x &gt;= 0 ? x : a * x), b)
    Parameters: a, b As an example, the TensorFlow Relu6 activation layer can be
    implemented by setting the parameter b to 6.0f:
    https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/relu6. For
    default behavior, set the value of a to 1.0f and the value of b to 6.0f.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="Method_Documentation"><a class="permalink" href="#Method_Documentation">Method
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">+ (nonnull <b>MPSNNNeuronDescriptor</b>*)
  cnnNeuronDescriptorWithType: (<b>MPSCNNNeuronType</b>) neuronType</h2>
<p class="Pp">Make a descriptor for a <b>MPSCNNNeuron</b> object.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>neuronType</i> The type of a neuron filter.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSNNNeuronDescriptor</b> object or
  nil, if failure.</div>
</section>
<section class="Ss">
<h2 class="Ss">+ (nonnull <b>MPSNNNeuronDescriptor</b>*)
  <b>cnnNeuronDescriptorWithType:</b> (<b>MPSCNNNeuronType</b>)
  neuronType(float) a</h2>
<p class="Pp">Make a descriptor for a <b>MPSCNNNeuron</b> object.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>neuronType</i> The type of a neuron filter.
<br/>
<i>a</i> Parameter 'a'.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSNNNeuronDescriptor</b> object or
  nil, if failure.</div>
</section>
<section class="Ss">
<h2 class="Ss">+ (nonnull <b>MPSNNNeuronDescriptor</b>*)
  <b>cnnNeuronDescriptorWithType:</b> (<b>MPSCNNNeuronType</b>)
  neuronType(float) a(float) b</h2>
<p class="Pp">Initialize the neuron descriptor.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>neuronType</i> The type of a neuron filter.
<br/>
<i>a</i> Parameter 'a'.
<br/>
<i>b</i> Parameter 'b'.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSNNNeuronDescriptor</b> object or
  nil, if failure.</div>
</section>
<section class="Ss">
<h2 class="Ss">+ (nonnull <b>MPSNNNeuronDescriptor</b>*)
  <b>cnnNeuronDescriptorWithType:</b> (<b>MPSCNNNeuronType</b>)
  neuronType(float) a(float) b(float) c</h2>
<p class="Pp">Make a descriptor for a <b>MPSCNNNeuron</b> object.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>neuronType</i> The type of a neuron filter.
<br/>
<i>a</i> Parameter 'a'.
<br/>
<i>b</i> Parameter 'b'.
<br/>
<i>c</i> Parameter 'c'.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSNNNeuronDescriptor</b> object or
  nil, if failure.</div>
</section>
<section class="Ss">
<h2 class="Ss">+ (nonnull <b>MPSNNNeuronDescriptor</b>*)
  cnnNeuronPReLUDescriptorWithData: (NSData *_Nonnull) data(bool) noCopy</h2>
<p class="Pp">Make a descriptor for a neuron of type MPSCNNNeuronTypePReLU. The
    PReLU neuron is the same as a ReLU neuron, except parameter 'a' is per
    feature channel.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>data</i> <b>A</b> NSData containing a float array with
  the per feature channel value of PReLu parameter. The number of float values
  in this array usually corresponds to number of output channels in a
  convolution layer. The descriptor retains the NSData object.
<br/>
<i>noCopy</i> An optimization flag that tells us whether the NSData allocation
  is suitable for use directly with no copying of the data into internal
  storage. This allocation has to match the same restrictions as listed for the
  newBufferWithBytesNoCopy:length:options:deallocator: method of
  MTLBuffer.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent"><b>A</b> valid <b>MPSNNNeuronDescriptor</b> object for a
  neuron of type MPSCNNNeuronTypePReLU or nil, if failure</div>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) init </h2>
<p class="Pp">You must use one of the interfaces below instead.</p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Property_Documentation"><a class="permalink" href="#Property_Documentation">Property
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- (float) a [read]<b>, [write]</b>, [nonatomic]<b>,
  [assign]</b></h2>
</section>
<section class="Ss">
<h2 class="Ss">- (float) b [read]<b>, [write]</b>, [nonatomic]<b>,
  [assign]</b></h2>
</section>
<section class="Ss">
<h2 class="Ss">- (float) c [read]<b>, [write]</b>, [nonatomic]<b>,
  [assign]</b></h2>
</section>
<section class="Ss">
<h2 class="Ss">- (NSData*) data [read]<b>, [write]</b>, [nonatomic]<b>,
  [retain]</b></h2>
</section>
<section class="Ss">
<h2 class="Ss">- (<b>MPSCNNNeuronType</b>) neuronType [read]<b>, [write]</b>,
  [nonatomic]<b>, [assign]</b></h2>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Author"><a class="permalink" href="#Author">Author</a></h1>
<p class="Pp">Generated automatically by Doxygen for
    MetalPerformanceShaders.framework from the source code.</p>
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">Mon Jul 9 2018</td>
    <td class="foot-os"><a href="..">Version MetalPerformanceShaders-119.3</a></td>
  </tr>
</table>
</body>
</html>
