<!DOCTYPE html>
<html>
<!-- This is an automatically generated file.  Do not edit.
   -*- nroff -*-
 -->
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <link rel="stylesheet" href="../style.css" type="text/css" media="all"/>
  <title>MPSNNFilterNode(3)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPSNNFilterNode(3)</td>
    <td class="head-vol">MetalPerformanceShaders.framework</td>
    <td class="head-rtitle">MPSNNFilterNode(3)</td>
  </tr>
</table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
<p class="Pp">MPSNNFilterNode</p>
</section>
<section class="Sh">
<h1 class="Sh" id="SYNOPSIS"><a class="permalink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<p class="Pp">#import &lt;MPSNNGraphNodes.h&gt;</p>
<p class="Pp">Inherits NSObject.</p>
<p class="Pp">Inherited by <b>MPSCNNBatchNormalizationNode</b>,
    <b>MPSCNNConvolutionNode</b>, <b>MPSCNNDilatedPoolingMaxNode</b>,
    <b>MPSCNNDropoutNode</b>, <b>MPSCNNInstanceNormalizationNode</b>,
    <b>MPSCNNLogSoftMaxNode</b>, <b>MPSCNNLossNode</b>, <b>MPSCNNNeuronNode</b>,
    <b>MPSCNNNormalizationNode</b>, <b>MPSCNNPoolingNode</b>,
    <b>MPSCNNSoftMaxNode</b>, <b>MPSCNNUpsamplingBilinearNode</b>,
    <b>MPSCNNUpsamplingNearestNode</b>, <b>MPSCNNYOLOLossNode</b>,
    <b>MPSNNBinaryArithmeticNode</b>, <b>MPSNNConcatenationNode</b>,
    <b>MPSNNGradientFilterNode</b>, and <b>MPSNNScaleNode</b>.</p>
<section class="Ss">
<h2 class="Ss" id="Instance_Methods"><a class="permalink" href="#Instance_Methods">Instance
  Methods</a></h2>
<br/>
<p class="Pp">(nonnull instancetype) - <b>init</b>
  <br/>
  (<b>MPSNNGradientFilterNode</b> *__nonnull) - <b>gradientFilterWithSource:</b>
  <br/>
  (<b>MPSNNGradientFilterNode</b> *__nonnull) -
    <b>gradientFilterWithSources:</b>
  <br/>
  (NSArray&lt; <b>MPSNNGradientFilterNode</b> * &gt; *__nonnull) -
    <b>gradientFiltersWithSources:</b>
  <br/>
  (NSArray&lt; <b>MPSNNGradientFilterNode</b> * &gt; *__nonnull) -
    <b>gradientFiltersWithSource:</b>
  <br/>
  (NSArray&lt; <b>MPSNNFilterNode</b> * &gt; *__nullable) -
    <b>trainingGraphWithSourceGradient:nodeHandler:</b>
  <br/>
  <br/>
</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Properties"><a class="permalink" href="#Properties">Properties</a></h2>
<br/>
<p class="Pp"><b>MPSNNImageNode</b> * <b>resultImage</b>
  <br/>
  <b>MPSNNStateNode</b> * <b>resultState</b>
  <br/>
  NSArray&lt; <b>MPSNNStateNode</b> * &gt; * <b>resultStates</b>
  <br/>
  id&lt; <b>MPSNNPadding</b> &gt; <b>paddingPolicy</b>
  <br/>
  NSString * <b>label</b>
  <br/>
  <br/>
</p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Detailed_Description"><a class="permalink" href="#Detailed_Description">Detailed
  Description</a></h1>
<p class="Pp"><b>A</b> placeholder node denoting a neural network filter stage
    There are as many <b>MPSNNFilterNode</b> subclasses as there are MPS neural
    network filter objects. Make one of those. This class defines an polymorphic
    interface for them.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="Method_Documentation"><a class="permalink" href="#Method_Documentation">Method
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- (NSArray &lt;<b>MPSNNGradientFilterNode</b>*&gt; * __nonnull)
  gradientFiltersWithSource: (<b>MPSNNImageNode</b> *__nonnull)
  gradientImage</h2>
<p class="Pp">Return multiple gradient versions of the filter MPSNNFilters that
    consume multiple inputs generally result in multiple conjugate filters for
    the gradient computation at the end of training. For example, a single
    concatenation operation that concatenates multple images will result in an
    array of slice operators that carve out subsections of the input gradient
    image.</p>
<p class="Pp">Reimplemented in <b>MPSNNGradientFilterNode</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (NSArray &lt;<b>MPSNNGradientFilterNode</b>*&gt; * __nonnull)
  gradientFiltersWithSources: (NSArray&lt; <b>MPSNNImageNode</b> * &gt;
  *__nonnull) gradientImages</h2>
<p class="Pp">Return multiple gradient versions of the filter MPSNNFilters that
    consume multiple inputs generally result in multiple conjugate filters for
    the gradient computation at the end of training. For example, a single
    concatenation operation that concatenates multple images will result in an
    array of slice operators that carve out subsections of the input gradient
    image.</p>
<p class="Pp">Reimplemented in <b>MPSNNBinaryArithmeticNode</b>, and
    <b>MPSNNGradientFilterNode</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (<b>MPSNNGradientFilterNode</b>*__nonnull)
  gradientFilterWithSource: (<b>MPSNNImageNode</b> *__nonnull)
  gradientImage</h2>
<p class="Pp">Return the gradient (backwards) version of this filter. The
    backwards training version of the filter will be returned. The non-gradient
    image and state arguments for the filter are automatically obtained from the
    target.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>gradientImage</i> The gradient images corresponding
  with the resultImage of the target</div>
<p class="Pp">Reimplemented in <b>MPSNNGradientFilterNode</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (<b>MPSNNGradientFilterNode</b>*__nonnull)
  gradientFilterWithSources: (NSArray&lt; <b>MPSNNImageNode</b> * &gt;
  *__nonnull) gradientImages</h2>
<p class="Pp">Return the gradient (backwards) version of this filter. The
    backwards training version of the filter will be returned. The non-gradient
    image and state arguments for the filter are automatically obtained from the
    target.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>gradientImages</i> The gradient images corresponding
  with the resultImage of the target</div>
<p class="Pp">Reimplemented in <b>MPSCNNYOLOLossNode</b>,
    <b>MPSNNConcatenationNode</b>, <b>MPSCNNLossNode</b>,
    <b>MPSNNBinaryArithmeticNode</b>, and <b>MPSNNGradientFilterNode</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (nonnull instancetype) init </h2>
<p class="Pp">Reimplemented in <b>MPSCNNNeuronGradientNode</b>, and
    <b>MPSCNNNeuronNode</b>.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (NSArray &lt;<b>MPSNNFilterNode</b>*&gt; * __nullable)
  trainingGraphWithSourceGradient: (<b>MPSNNImageNode</b> *__nullable)
  gradientImage(__nullable <b>MPSGradientNodeBlock</b>) nodeHandler</h2>
<p class="Pp">Build training graph from inference graph This method will
    iteratively build the training potion of a graph based on an inference
    graph. Self should be the last node in the inference graph. It is typically
    a loss layer, but can be anything. Typically, the 'inference graph' used
    here is the desired inference graph with a dropout node and a loss layer
    node appended.</p>
<p class="Pp">BUG: This method can not follow links to regions of the graph that
    are connected to the rest of the graph solely via MPSNNStateNodes. <b>A</b>
    gradient image input is required to construct a
    <b>MPSNNGradientFilterNode</b> from a inference filter node.</p>
<p class="Pp"><b>Parameters:</b></p>
<div class="Bd-indent"><i>gradientImage</i> The input gradient image for the
  first gradient node in the training section of the graph. If nil,
  self.resultImage is used. This results in a standard monolithic training
  graph. If the graph is instead divided into multiple subgraphs (potentially to
  allow for your custom code to appear inbetween <b>MPSNNGraph</b> segments) a
  new MPSImageNode* may be substituted.
<br/>
<i>nodeHandler</i> An optional block to allow for customization of gradient
  nodes and intermediate images as the graph is constructed. It may also be used
  to prune braches of the developing training graph. If nil, the default handler
  is used. It builds the full graph, and assigns any
  inferenceNodeSources[i].handle to their gradient counterparts.</div>
<p class="Pp"><b>Returns:</b></p>
<div class="Bd-indent">The list of new <b>MPSNNFilterNode</b> training graph
  termini. These MPSNNFilterNodes are not necessarily all
  MPSNNGradientFilterNodes. To build a full list of nodes created, use a custom
  nodeHandler. If no nodes are created nil is returned.</div>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Property_Documentation"><a class="permalink" href="#Property_Documentation">Property
  Documentation</a></h1>
<section class="Ss">
<h2 class="Ss">- label [read]<b>, [write]</b>, [atomic]<b>, [copy]</b></h2>
<p class="Pp"><b>A</b> string to help identify this object.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (id&lt;<b>MPSNNPadding</b>&gt;) paddingPolicy [read]<b>,
  [write]</b>, [nonatomic]<b>, [retain]</b></h2>
<p class="Pp">The padding method used for the filter node The padding policy
    configures how the filter centers the region of interest in the source
    image. It principally is responsible for setting the
    <b>MPSCNNKernel.offset</b> and the size of the image produced, and sometimes
    will also configure .sourceFeatureChannelOffset,
    .sourceFeatureChannelMaxCount, and .edgeMode. It is permitted to set any
    other filter properties as needed using a custom padding policy. The default
    padding policy varies per filter to conform to consensus expectation for the
    behavior of that filter. In some cases, pre-made padding policies are
    provided to match the behavior of common neural networking frameworks with
    particularly complex or unexpected behavior for specific nodes. See
    <b>MPSNNDefaultPadding</b> class methods in <b>MPSNeuralNetworkTypes.h</b>
    for more.</p>
<p class="Pp">BUG: MPS doesn't provide a good way to reset the <b>MPSKernel</b>
    properties in the context of a <b>MPSNNGraph</b> after the kernel is
    finished encoding. These values carry on to the next time the graph is used.
    Consequently, if your custom padding policy modifies the property as a
    function of the previous value, e.g.:</p>
<p class="Pp"></p>
<pre>kernel.someProperty += 2;
</pre>
<p class="Pp">then the second time the graph runs, the property may have an
    inconsistent value, leading to unexpected behavior. The default padding
    computation runs before the custom padding method to provide it with a sense
    of what is expected for the default configuration and will reinitialize the
    value in the case of the .offset. However, that computation usually doesn't
    reset other properties. In such cases, the custom padding policy may need to
    keep a record of the original value to enable consistent behavior.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (<b>MPSNNImageNode</b>*) resultImage [read]<b>,
  [nonatomic]</b>, [assign]<b></b></h2>
<p class="Pp">Get the node representing the image result of the filter Except
    where otherwise noted, the precision used for the result image (see format
    property) is copied from the precision from the first input image node.</p>
</section>
<section class="Ss">
<h2 class="Ss">- (<b>MPSNNStateNode</b>*) resultState [read]<b>,
  [nonatomic]</b>, [assign]<b></b></h2>
<p class="Pp">convenience method for resultStates[0] If resultStates is nil,
    returns nil</p>
</section>
<section class="Ss">
<h2 class="Ss">- (NSArray&lt;<b>MPSNNStateNode</b>*&gt;*) resultStates
  [read]<b>, [nonatomic]</b>, [assign]<b></b></h2>
<p class="Pp">Get the node representing the state result of the filter If more
    than one, see description of subclass for ordering.</p>
<p class="Pp"></p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="Author"><a class="permalink" href="#Author">Author</a></h1>
<p class="Pp">Generated automatically by Doxygen for
    MetalPerformanceShaders.framework from the source code.</p>
</section>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">Mon Jul 9 2018</td>
    <td class="foot-os">Version MetalPerformanceShaders-119.3</td>
  </tr>
</table>
</body>
</html>
